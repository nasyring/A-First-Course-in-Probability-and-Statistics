# Hypothesis Testing

So far our discussion of statistical inference has been limited to "estimation", which is essentially any method that determines which parameter values match/agree with observed data.  We have discussed both parametric and non-parametric estimation, although we have not used those terms.  Non-parametric estimation refers to estimation of population parameters without specifying any probability model for the data.  For example, the sample mean is a reasonable estimator of the population mean (should it exist) regardless of the sampling distribution of the data (the population distribution).  Parametric estimators are tied to assumed sampling distributions.  For example, maximum likelihood estimators totally rely on an assumed sampling distribution of the data (population distribution).  Parametric estimation can be viewed as selecting which particular probability model within a given set (the assumed distribution) best fits the data.
<br><br>

We'll next expand our discussion of statistical inference to ask a different, but related question.  Instead of asking which parameters/model distributions agree with a given data set, we ask "how much evidence does a given data set provide for a particular parameter value or set of parameter values?"  The particular parameter values are referred to as the hypothesis or "null hypothesis". And, a procedure that determines whether the data provides sufficient evidence against the null hypothesis so as to make it implausible is called a "hypothesis test".   


## Notation

Consider a generic parameter $\theta$ taking values in some set $\Theta$.  The null hypothesis $\theta$ takes exactly the value $\theta_0$ is written $H_0: \theta = \theta_0$.  Its complement is the alternative hypothesis $H_a: \theta\ne\theta_0$, which is always the set complement of the null hypothesis.  In particular, $H_0: \theta = \theta_0$ is called a "point-null hypothesis" because the set in the null hypothesis consists of only a single point.  In other cases, the null hypothesis is "composite", e.g., $H_0:\theta \leq \theta_0$ versus $H_a: \theta > \theta_0$.    

Example: Suppose an experiment consist of collecting a random sample from a normal population with unknown mean $\mu$ and unknown variance $\sigma^2$.  A point null hypothesis that $\mu = 0$ is phrased $H_0: \mu = 0$ versus the alternative hypothesis $\mu \ne 0$.  A point null hypothesis that $\sigma^2 = 1$ is phrased $H_0:\sigma^2=1$ versus $H_a:\sigma^2 \ne 1$, where the alternative hypothesis tacitly assumes $\sigma^2>0$.  

## Hypothesis testing outcomes

A hypothesis testing procedure begins with a pair of null and alternative hypotheses.  Next, data relevant to the hypotheses is collected, and a decision is made as to whether the data provides sufficient evidence against the null hypothesis such that it may be rejected as implausible.  Otherwise, the data are viewed as sufficiently consistent with the null hypothesis as to retain it.<br><br>

As such, there are four possible outcomes of this procedure.  In two cases, the correct decision is made: either the null hypothesis is true and it is retained, or the null hypothesis is false and it is reject.  There are two corresponding errors:
1) A Type 1 error is committed when the null hypothesis is true but it is rejected; and,
2) A Type 2 error is committed when the null hypothesis is false and it is retained.<br><br>

Since the decision to reject or retain the null hypothesis is based on a random sample of data, the decision is itself random; so, each of these outcomes has a certain probability of occuring.  Given the null hypothesis is true, the chance of a Type 1 error occurring is denoted $\alpha$ and is also called the Type 1 error rate.  Given the null hypothesis is false the chance of a Type 2 error occurring is denoted $\beta$, and its complement, the chance of rejecting $H_0$ is denoted $1-\beta$ and referred to as the "power of the test".  <br><br>

Of course, it would be nice if one could eliminate any chance of an error occurring, but that is not possible.  To see this, consider the extreme case of a non-random hypothesis test that always rejects the null hypothesis, no matter the data.  Such a rule minimizes the chance of a Type 2 error (in fact there is such chance) but maximizes the chance of a Type 1 error.  And, the opposite extreme, in which the null hypothesis is always retained similarly minimizes Type 1 error at the cost of maximizing Type 2 errors.  Any testing procedure in between necessarily has some positive chance of each type of error.  <br><br>

As we will see, it is possible to construct hypothesis tests with an explicit cap (upper bound) on the Type 1 error rate $\alpha$.  This means that, whenever possible, it makes sense to design experiments and hypotheses such that Type 1 errors are more serious than Type 2 errors, so that they may be expressly controlled.  A hypothesis test that limits $\alpha$ to a prespecified level is called a "level-$\alpha$ test".  

## Tests based on a normal population

### Test for a normal mean when the variance is known

Suppose a given population is known to follow a normal distribution with an unknown mean and a known variance $\sigma^2$.  We wish to test the point null hypothesis $H_0:\mu = \mu_0$ for some given number $\mu_0$ versus the alternative $H_a:\mu \ne \mu_0$.  And, we wish our test to limit the Type 1 error rate to a given level $\alpha$, say, $5\%$.  <br><br>

We obtain a random sample of size $n$ from the population.  How should we proceed?  If $H_0$ is true, then our data should look like it came from $N(\mu_0, \sigma^2)$; specifically, the sample mean should be "close" to $\mu_0$.  If $\overline X$ is close to $\mu_0$, then $H_0$ seems plausible, otherwise not.  Our intuition says our test should look like: "reject $H_0$ if $|\overline X-\mu_0|>c$" for some cutoff $c>0$.  The constraint on Type 1 error rate to be no more than $\alpha$ is enough to determine $c$:
\begin{align*}
1-\alpha &= P(-c\leq \overline X - \mu_0 \leq c)\\
& = P(-c/\sqrt{\sigma^2/n} \leq Z \leq c/\sqrt{\sigma^2/n})
\end{align*}
This implies we should reject $H_0$ if $|Z|>z_{1-\alpha/2}$ where
\[Z = \frac{\overline X - \mu_0}{\sqrt{\sigma^2/n}}\]
is the standardized sample mean assuming $H_0$ is true (often it is said, "under $H_0$").  <br><br>

Next, we investigate the power of this test.  Recall the power is the probability the test rejects the null hypothesis when the null is false.  For most tests, like the current one, the null hypothesis may be false in many ways.  If $H_0$ is false then $\mu\ne \mu_0$, so $\mu$ is some other number, lets say $y$.  Intuitively, for $y$ values close to $\mu_0$ we would not necessarily expect to notice $H_0$ is false, but for $y$ values far from $\mu_0$ we would expect $\overline X$ to be far from $\mu_0$ and for the test to reject $\mu_0$.  So, we expect the power to be a function of $y$ and to be increasing as a function of $|y-\mu_0|$.  Below we compute this power function:
\begin{align*}
P\left(\frac{\overline X - \mu_0}{\sigma/\sqrt{n}} < z_{\alpha/2}|\mu = y\right) & =  P\left(\frac{\overline X - y}{\sigma/\sqrt{n}} < z_{\alpha/2}+\frac{\mu_0-y}{\sigma/\sqrt{n}}\right)\\
& = P\left(Z < z_{\alpha/2}+\frac{\mu_0-y}{\sigma/\sqrt{n}}\right).
\end{align*}
\begin{align*}
P\left(z_{1-\alpha/2} < \frac{\overline X - \mu_0}{\sigma/\sqrt{n}}|\mu = y\right) & =  P\left(z_{1-\alpha/2}+\frac{\mu_0-y}{\sigma/\sqrt{n}}<\frac{\overline X - y}{\sigma/\sqrt{n}}\right)\\
& = P\left(z_{1-\alpha/2}+\frac{\mu_0-y}{\sigma/\sqrt{n}} < Z\right)\\
& = 1-P\left(Z < z_{1-\alpha/2}+\frac{\mu_0-y}{\sigma/\sqrt{n}}\right).
\end{align*}
Therefore, the power as a function of $y$ is
\[(1-\beta) = P\left(Z < z_{\alpha/2}+\frac{\mu_0-y}{\sigma/\sqrt{n}}\right)+1-P\left(Z < z_{1-\alpha/2}+\frac{\mu_0-y}{\sigma/\sqrt{n}}\right).\]
We illustrate this power function below for $H_0:\mu = 1$ where $\sigma^2 = 2$, $n=10$, and $\alpha = 0.05$.

```{r, echo = T, eval = T}
alpha <- 0.05
mu0 <- 1
sigma2 <- 2
n <- 10
power <- function(y) pnorm(qnorm(alpha/2)+(1-y)/sqrt(sigma2/n))+1-pnorm(qnorm(1-alpha/2)+(1-y)/sqrt(sigma2/n))
curve(power, from = -5, to = 6, xlab = 'y', ylab = 'power(y)')  
```

The power is minimized (and equal to 0.05) at $y = \mu_0$ where the test only rejects at rate $\alpha$ by design.  The power increases smoothly and symetrically as a function of $|y-\mu_0|$ until the test has nearly a $100\%$ chance of rejecting $H_0$ for true mean sufficiently far from $\mu_0$.  


### Test for a normal mean when the variance is unknown

As we have discussed many times when the population variance is unknown the Studentized sample mean has a Student's $t$ distribution with $n-1$ degrees of freedom.  A Student's $t-$based test for $H_0:\mu = \mu_0$ versus $H_a:\mu\ne\mu_0$ is essentially the same as the above test but based on the $T$ statistic, $T = \frac{\overline X - \mu_0}{S/\sqrt{n}}$ rather than the $Z$ statistic $Z = \frac{\overline X - \mu_0}{\sigma/\sqrt{n}}$.  A level-$\alpha$ test rejects $H_0$ if $T > t_{1-\alpha/2}(n-1)$ or $T < t_{\alpha/2}(n-1)$, where $t_\alpha(df)$ is the Student's $t$ lower $\alpha$ quantile with $df$ degrees of freedom.  <br><br>

For a different angle, consider the test of the one-sided (composite) hypotheses $H_0:\mu \leq \mu_0$ versus $H_a:\mu > \mu_0$.  Naturally, values of $\overline X$ smaller than $\mu_0$ lend support to the null hypothesis, so a level $\alpha$ test of $H_0$ only rejects the null if $T > t_{1-\alpha}(n-1)$.  Consider the power of this one-sided test.  Since the test only rejects for large values of $\overline X$, the power should increase as $T$ increases.  Mimicking (half of) our power calculation for the $Z$ test above we have
\[1-\beta = P\left(\frac{\overline X - y}{S/\sqrt{n}} + \frac{y - \mu_0}{S/\sqrt{n}} > t_{1-\alpha}(n-1)\right).\]
The random variable $\frac{\overline X - y}{S/\sqrt{n}} + \frac{y - \mu_0}{S/\sqrt{n}}$ has a Student's $t$ distribution with $n-1$ degrees of freedom and **non-centrality parameter** $y-\mu_0$.  

```{r, echo = T, eval = T}
alpha <- 0.05
mu0 <- 1
sigma2 <- 2
n <- 10
power <- function(y)  1-pt(qt(1-alpha, n-1), df = n-1, ncp = y - mu0)
curve(power, from = -5, to = 6, xlab = 'y', ylab = 'power(y)')  
```


### Test for a normal population variance

Consider a test that rejects the null hypothesis $H_0:\sigma^2 \leq \sigma_0^2$ if $\frac{(n-1)S^2}{\sigma_0^2} \geq  \chi^2_{1-\alpha}(n-1)$ where $\chi^2_{\alpha}(df)$ is the Chi-squared lower $\alpha$ quantile for a Chi-squared distribution with df degrees of freedom.  Such a rejection rule defines a level-$\alpha$ test:
\[P\left(\frac{(n-1)S^2}{\sigma_0^2} \geq  \chi^2_{1-\alpha}(n-1)|\sigma^2 = \sigma_0^2\right) = P\left(\chi^{2}(n-1) \geq  \chi^2_{1-\alpha}(n-1)\right) = \alpha,\]
by definition.  We can compute the power curve of such a test:
\begin{align*}
P\left(\frac{(n-1)S^2}{\sigma_0^2} \geq  \chi^2_{1-\alpha}(n-1)|\sigma^2 = y\right) & = P\left(\frac{(n-1)S^2}{y} \geq  \frac{\sigma_0^2}{y}\chi^2_{1-\alpha}(n-1)\right)\\
& = P\left(\chi^2(n-1) \geq  \frac{\sigma_0^2}{y}\chi^2_{1-\alpha}(n-1)\right)
\end{align*}

```{r, echo = T, eval = T}
alpha <- 0.05
mu0 <- 1
sigma2 <- 2
n <- 10
power <- function(y)  1-pchisq((2/y)*qchisq(1-alpha, n-1),n-1)
curve(power, from = 2, to = 14, xlab = 'y', ylab = 'power(y)')  
```




### Tests for a difference of normal population means

Suppose $X_1, \ldots, X_n$ and $Y_1, \ldots, Y_m$ are random samples from two normal populations with unknown means and variances $\mu_x$, $\mu_y$, $\sigma_x^2$, and $\sigma_y^2$.  Consider testing the point-null hypothesis $H_0:\mu_x - \mu_y = \Delta$ versus $H_a:\mu_x - \mu_y \ne \Delta$ for a given constant $\Delta$.  Following our previous strategies, the test decision should be based on one of the two statistics
\[T = \frac{\overline X - \overline Y - \Delta}{\sqrt{S_x^2/n + S_y^2/m}} \quad \text{or}\quad T_p = \frac{\overline X - \overline Y - \Delta}{\sqrt{S_p^2\left(1/n+1/m\right)}}.\]
Under the null hypothesis, $T_p$ is exactly $t$ distributed with $n+m-2$ df if $\sigma_x^2 = \sigma_y^2$, and under the null hypothesis $T$ is approximately $t$ distributed with the Welch-Satterthwaite choice of df.  These two statistics, $T_p$ and $T$, are the basis for the pooled Student's $t$ test and Welch's unpooled test for $\mu_x - \mu_y$.  For either test, we reject $H_0$ if the test statistic is too large in absolute value, i.e., $|T_p|>t_{1-\alpha/2}(n+m-2)$.  The Welch test is usually the better choice because, as we have previously seen, Student's pooled CIs perform may poorly when $n\ne m$ and $\sigma_x^2 \ne \sigma_y^2$, and the Student's $t$ test experiences the same problems.  <br><br>

These two-sample t-tests may be performed using R's built-in t.test function:

```{r, echo = T, eval = T}
set.seed(12345)
X <- rnorm(13, 5, 2)
Y <- rnorm(19, 4, 1)
# testing a point null with Delta = 1, alpha = 0.05
t.test(X,Y,alternative = 'two.sided',mu=1,var.equal=FALSE,conf.level = 0.95)
t.test(X,Y,alternative = 'two.sided',mu=1,var.equal=TRUE,conf.level = 0.95)
```

The t.test function returns a "p-value" which is defined as the null-hypothesis-true probability of observing the observed test statistic or a more extreme value.  In other words, it is equal to the equivalent $\alpha$ for which the observed test statistic lies on the boundary of the reject/retain criterion.  For example, Welch's test gives a p-value of 0.8171.  The test statistic is
\[T = \frac{5.114192-4.243719-1}{\sqrt{3.18206/13 + 1.137897/19}}=-0.2346661.\]
And, the Welch-Satterthwaite df is 17.877 according to t.test.  For a test statistic value of -0.2346661 to be borderline for rejection means the upper $t(17.877)$ quantile for rejection would equal 0.2346661.  Using the $pt$ function we have $(1-pt(0.2346661,17.877)) = 0.4085673$ which constitutes the probability on one half of the symmetric "rejection region", so that the p-value is twice this number, or $0.8171347$, as given by t.test. 
```{r, echo = T, eval = T}
(1-pt(0.2346661,17.877))
```















